# newtrain.py (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå d1, d2, d3)

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# ==========================
# üîπ 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path ‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
# ==========================
dataset_dir = "datasetnewcrop"  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏à‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
img_size = (224, 224)
batch_size = 64
epochs = 6

# ‡∏î‡∏∂‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå (‡πÄ‡∏ä‡πà‡∏ô d1, d2, d3 ‚Üí 3 ‡∏Ñ‡∏•‡∏≤‡∏™)
class_names = sorted(os.listdir(dataset_dir))
num_classes = len(class_names)  # ‡πÄ‡∏ä‡πà‡∏ô 3 ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ d1, d2, d3
print(f"‚úÖ ‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ñ‡∏•‡∏≤‡∏™: {class_names} ‚Üí ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™ = {num_classes}")

# ==========================
# üîπ 2. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û
# ==========================
X, y = [], []

for class_name in class_names:
    class_path = os.path.join(dataset_dir, class_name)
    if not os.path.isdir(class_path):
        print(f"‚ö†Ô∏è ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏°‡πà‡∏û‡∏ö: {class_path}")
        continue

    for filename in os.listdir(class_path):
        if filename.lower().endswith((".jpg", ".jpeg", ".png")):
            img_path = os.path.join(class_path, filename)
            img = load_img(img_path, target_size=img_size)
            img_array = img_to_array(img) / 255.0
            X.append(img_array)
            # ‡πÅ‡∏õ‡∏•‡∏á d1 ‚Üí 1 ‚Üí 0, d2 ‚Üí 2 ‚Üí 1, d3 ‚Üí 3 ‚Üí 2
            y.append(int(class_name[1:]) - 1)

X = np.array(X)
y = np.array(y)
y = to_categorical(y, num_classes=num_classes)  # ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ y ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [0, num_classes-1]

# ==========================
# üîπ 3. ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# ==========================
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42, shuffle=True
)

# ==========================
# üîπ 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
# ==========================
model = Sequential(
    [
        Conv2D(32, (3, 3), activation="relu", input_shape=(224, 224, 3)),
        MaxPooling2D(2, 2),
        Conv2D(64, (3, 3), activation="relu"),
        MaxPooling2D(2, 2),
        Conv2D(128, (3, 3), activation="relu"),
        MaxPooling2D(2, 2),
        Conv2D(128, (3, 3), activation="relu"),
        MaxPooling2D(2, 2),
        Flatten(),
        Dense(512, activation="relu"),
        Dropout(0.5),
        Dense(256, activation="relu"),
        Dropout(0.3),
        Dense(num_classes, activation="softmax"),
    ]
)

model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

# ==========================
# üîπ 5. ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (train)
# ==========================
print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡∏®‡∏π‡∏ô‡∏¢‡πå...")
history = model.fit(
    X_train,
    y_train,
    epochs=epochs,
    batch_size=batch_size,
    validation_data=(X_val, y_val),
    verbose=1,
)

# ==========================
# üîπ 6. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
# ==========================
os.makedirs("saved_model", exist_ok=True)
model.save("saved_model/newsimple_model.h5")
print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏µ‡πà saved_model/newsimple_model.h5")
print(f"üéâ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {num_classes} ‡∏Ñ‡∏•‡∏≤‡∏™ (d1, d2, ..., d{num_classes})!")
